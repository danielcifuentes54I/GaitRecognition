{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "''''Autores: Daniel Esteban Cifuentes Cossio\n",
    "             Cristian Cano Osorio\n",
    "    Asesor:  Pedro A'''\n",
    "\n",
    "''''Carga de librerias necesarias'''\n",
    "\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications import vgg16\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pedro Atencio\n",
    "2018\n",
    "\n",
    "Este ejemplo extrae la activacion de la pernultima capa\n",
    "de una red neuronal profunda pre-entrenada. En este caso\n",
    "VGG16. Utilizand Keras es posible utilizar otras redes\n",
    "tales como VGG19 o ResNet50.\n",
    "\n",
    "En este codigo se utilizo Keras 2.1.6, Tensorflow 1.8.0\n",
    "'''\n",
    "\n",
    "def obtenerActivacion(img):\n",
    "\n",
    "    #3. Cargamos la imagen y la pre-procesamos\n",
    "\n",
    "    #img = imread('baboon.bmp')\n",
    "\n",
    "    x = resize(img, output_shape=(224, 224))\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x.astype(np.float64)*255.0\n",
    "    x = x = preprocess_input(x)\n",
    "\n",
    "    #4. Enviamos la imagen al modelo y obtenemos el vector de activacion de la penultima capa\n",
    "    deep_feature = vgg16_int_model.predict(x)\n",
    "    return deep_feature\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Método para traer la intersección de una imagen a color y otra\n",
    "###a blanco y negro\n",
    "\n",
    "def transformarImagen(rutaColor,rutaBlancoNegro):\n",
    "        \n",
    "    imagenColor = imread(rutaColor)\n",
    "    imagenBN = imread(rutaBlancoNegro)\n",
    "    imcv = cv2.bitwise_and(imagenColor[:,:,0],imagenBN,1)\n",
    "    imcv2 = cv2.bitwise_and(imagenColor[:,:,1],imagenBN,1)\n",
    "    imcv3 = cv2.bitwise_and(imagenColor[:,:,2],imagenBN,1)\n",
    "        \n",
    "    rgbArray = np.zeros((480,640,3), 'uint8')\n",
    "\n",
    "    rgbArray[..., 0] = imcv\n",
    "    rgbArray[..., 1] = imcv2\n",
    "    rgbArray[..., 2] = imcv3\n",
    "    img = Image.fromarray(rgbArray)  \n",
    "    image = np.asarray(img, dtype=np.uint8)\n",
    "    #image = image[:, :, :3]\n",
    "    return (image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveMatrix(name, path, matrix):\n",
    "    sv=path+name\n",
    "    with open(sv,'wb') as fp:\n",
    "        pk.dump(matrix,fp)\n",
    "\n",
    "def loadMatrix(name, path):\n",
    "    sv=path+name\n",
    "    with open(sv,'rb') as fp:\n",
    "        return pk.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_size(path):\n",
    "    files = listdir(path)\n",
    "    \n",
    "    number_of_folders = 0\n",
    "    for f in files:\n",
    "        number_of_folders += 1\n",
    "    \n",
    "    return number_of_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenes procesadas:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenes procesadas:  2\n",
      "imagenes procesadas:  3\n",
      "imagenes procesadas:  4\n",
      "imagenes procesadas:  5\n",
      "imagenes procesadas:  6\n",
      "imagenes procesadas:  7\n",
      "imagenes procesadas:  8\n",
      "imagenes procesadas:  9\n",
      "imagenes procesadas:  10\n",
      "imagenes procesadas:  11\n",
      "imagenes procesadas:  12\n",
      "imagenes procesadas:  13\n",
      "imagenes procesadas:  14\n",
      "imagenes procesadas:  15\n",
      "imagenes procesadas:  16\n",
      "imagenes procesadas:  17\n",
      "imagenes procesadas:  18\n",
      "imagenes procesadas:  19\n",
      "imagenes procesadas:  20\n",
      "imagenes procesadas:  21\n",
      "imagenes procesadas:  22\n",
      "imagenes procesadas:  23\n",
      "imagenes procesadas:  24\n",
      "imagenes procesadas:  25\n",
      "imagenes procesadas:  26\n",
      "imagenes procesadas:  27\n",
      "imagenes procesadas:  28\n",
      "imagenes procesadas:  29\n",
      "imagenes procesadas:  30\n",
      "imagenes procesadas:  31\n",
      "imagenes procesadas:  32\n",
      "imagenes procesadas:  33\n",
      "imagenes procesadas:  34\n",
      "imagenes procesadas:  35\n",
      "imagenes procesadas:  36\n",
      "imagenes procesadas:  37\n",
      "imagenes procesadas:  38\n",
      "imagenes procesadas:  39\n",
      "imagenes procesadas:  40\n",
      "imagenes procesadas:  41\n",
      "imagenes procesadas:  42\n",
      "imagenes procesadas:  43\n",
      "imagenes procesadas:  44\n",
      "imagenes procesadas:  45\n",
      "imagenes procesadas:  46\n",
      "imagenes procesadas:  47\n",
      "imagenes procesadas:  48\n",
      "imagenes procesadas:  49\n",
      "imagenes procesadas:  50\n",
      "imagenes procesadas:  51\n",
      "imagenes procesadas:  52\n",
      "imagenes procesadas:  53\n",
      "imagenes procesadas:  54\n",
      "imagenes procesadas:  55\n",
      "imagenes procesadas:  56\n",
      "imagenes procesadas:  57\n",
      "imagenes procesadas:  58\n",
      "imagenes procesadas:  59\n",
      "imagenes procesadas:  60\n",
      "imagenes procesadas:  61\n",
      "imagenes procesadas:  62\n",
      "imagenes procesadas:  63\n",
      "imagenes procesadas:  64\n",
      "imagenes procesadas:  65\n",
      "imagenes procesadas:  66\n",
      "imagenes procesadas:  67\n",
      "imagenes procesadas:  68\n",
      "imagenes procesadas:  69\n",
      "imagenes procesadas:  70\n",
      "imagenes procesadas:  71\n",
      "imagenes procesadas:  72\n",
      "imagenes procesadas:  73\n",
      "imagenes procesadas:  74\n",
      "imagenes procesadas:  75\n",
      "imagenes procesadas:  76\n",
      "imagenes procesadas:  77\n",
      "imagenes procesadas:  78\n",
      "imagenes procesadas:  79\n",
      "imagenes procesadas:  80\n",
      "imagenes procesadas:  81\n",
      "imagenes procesadas:  82\n",
      "imagenes procesadas:  83\n",
      "imagenes procesadas:  84\n",
      "imagenes procesadas:  85\n",
      "imagenes procesadas:  86\n",
      "imagenes procesadas:  87\n",
      "imagenes procesadas:  88\n",
      "imagenes procesadas:  89\n",
      "imagenes procesadas:  90\n",
      "imagenes procesadas:  91\n",
      "imagenes procesadas:  92\n",
      "imagenes procesadas:  93\n",
      "imagenes procesadas:  94\n",
      "imagenes procesadas:  95\n",
      "imagenes procesadas:  96\n",
      "imagenes procesadas:  97\n",
      "imagenes procesadas:  98\n",
      "imagenes procesadas:  99\n",
      "imagenes procesadas:  100\n",
      "imagenes procesadas:  101\n",
      "imagenes procesadas:  102\n",
      "imagenes procesadas:  103\n",
      "imagenes procesadas:  104\n",
      "imagenes procesadas:  105\n",
      "imagenes procesadas:  106\n",
      "imagenes procesadas:  107\n",
      "imagenes procesadas:  108\n",
      "imagenes procesadas:  109\n",
      "imagenes procesadas:  110\n",
      "imagenes procesadas:  111\n",
      "imagenes procesadas:  112\n",
      "imagenes procesadas:  113\n",
      "imagenes procesadas:  114\n",
      "imagenes procesadas:  115\n",
      "imagenes procesadas:  116\n",
      "imagenes procesadas:  117\n",
      "imagenes procesadas:  118\n",
      "imagenes procesadas:  119\n",
      "imagenes procesadas:  120\n",
      "imagenes procesadas:  121\n",
      "imagenes procesadas:  122\n",
      "imagenes procesadas:  123\n",
      "imagenes procesadas:  124\n",
      "imagenes procesadas:  125\n",
      "imagenes procesadas:  126\n",
      "imagenes procesadas:  127\n",
      "imagenes procesadas:  128\n",
      "imagenes procesadas:  129\n",
      "imagenes procesadas:  130\n",
      "imagenes procesadas:  131\n",
      "imagenes procesadas:  132\n",
      "imagenes procesadas:  133\n",
      "imagenes procesadas:  134\n",
      "imagenes procesadas:  135\n",
      "imagenes procesadas:  136\n",
      "imagenes procesadas:  137\n",
      "imagenes procesadas:  138\n",
      "imagenes procesadas:  139\n",
      "imagenes procesadas:  140\n",
      "imagenes procesadas:  141\n",
      "imagenes procesadas:  142\n",
      "imagenes procesadas:  143\n",
      "imagenes procesadas:  144\n",
      "imagenes procesadas:  145\n",
      "imagenes procesadas:  146\n",
      "imagenes procesadas:  147\n",
      "imagenes procesadas:  148\n",
      "imagenes procesadas:  149\n",
      "imagenes procesadas:  150\n",
      "imagenes procesadas:  151\n",
      "imagenes procesadas:  152\n",
      "imagenes procesadas:  153\n",
      "imagenes procesadas:  154\n",
      "imagenes procesadas:  155\n",
      "imagenes procesadas:  156\n",
      "imagenes procesadas:  157\n",
      "imagenes procesadas:  158\n",
      "imagenes procesadas:  159\n",
      "imagenes procesadas:  160\n",
      "imagenes procesadas:  161\n",
      "imagenes procesadas:  162\n",
      "imagenes procesadas:  163\n",
      "imagenes procesadas:  164\n",
      "imagenes procesadas:  165\n",
      "imagenes procesadas:  166\n",
      "imagenes procesadas:  167\n",
      "imagenes procesadas:  168\n",
      "imagenes procesadas:  169\n",
      "imagenes procesadas:  170\n",
      "imagenes procesadas:  171\n",
      "imagenes procesadas:  172\n",
      "imagenes procesadas:  173\n",
      "imagenes procesadas:  174\n",
      "imagenes procesadas:  175\n",
      "imagenes procesadas:  176\n",
      "imagenes procesadas:  177\n",
      "imagenes procesadas:  178\n",
      "imagenes procesadas:  179\n",
      "imagenes procesadas:  180\n",
      "imagenes procesadas:  181\n",
      "imagenes procesadas:  182\n",
      "imagenes procesadas:  183\n",
      "imagenes procesadas:  184\n",
      "imagenes procesadas:  185\n",
      "imagenes procesadas:  186\n",
      "imagenes procesadas:  187\n",
      "imagenes procesadas:  188\n",
      "imagenes procesadas:  189\n",
      "imagenes procesadas:  190\n",
      "imagenes procesadas:  191\n",
      "imagenes procesadas:  192\n",
      "imagenes procesadas:  193\n",
      "imagenes procesadas:  194\n",
      "imagenes procesadas:  195\n",
      "imagenes procesadas:  196\n",
      "imagenes procesadas:  197\n",
      "imagenes procesadas:  198\n",
      "imagenes procesadas:  199\n",
      "imagenes procesadas:  200\n",
      "imagenes procesadas:  201\n",
      "imagenes procesadas:  202\n",
      "imagenes procesadas:  203\n",
      "imagenes procesadas:  204\n",
      "imagenes procesadas:  205\n"
     ]
    }
   ],
   "source": [
    "#1. Cargamos el modelo completo\n",
    "vgg16_model = vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "\n",
    "#2. Creamos el modelo intermedio (penultima capa) a partir del modelo completo\n",
    "vgg16_int_model = Model(inputs=vgg16_model.input, outputs = vgg16_model.get_layer('fc2').output)\n",
    "\n",
    "\n",
    "\n",
    "pathFolderRoot = \"E:/ITM/Semillero de investigación/FirstTestData\"\n",
    "pathFolderResult = \"E:/ITM/Semillero de investigación/FirstTestData/Result/\"\n",
    "pathImagesColor = pathFolderRoot+\"/Color/A/tr01_cam00/\"\n",
    "pathImagesSegment = pathFolderRoot+\"/Segmentado/A/tr01_cam00/\"\n",
    "totalPersons = get_dataset_size(\"E:\\ITM\\Semillero de investigación\\FirstTestData\\Color\")\n",
    "    \n",
    "imagesColor = listdir(pathImagesColor)\n",
    "imagesSegment = listdir(pathImagesSegment)\n",
    "matrixTotal =0\n",
    "i = 0\n",
    "\n",
    "for img in imagesColor:\n",
    "    if (int(img.split(\".\")[0]) > 169):\n",
    "        ##se obtiene cada imagén\n",
    "        i = i +1\n",
    "        imgColor = imread(pathImagesColor+img)\n",
    "        imgSegment = imread(pathImagesSegment+img)\n",
    "        print(\"imagenes procesadas: \" ,i)\n",
    "        ##Se obtiene la intersección de las imagenes\n",
    "        imgTransform = transformarImagen(pathImagesColor+img,pathImagesSegment+img)\n",
    "        vector = obtenerActivacion(imgTransform)\n",
    "        ##se verifica si es la primera iamgen a procesar\n",
    "        #if(int(img.split(\".\")[0]) > 169 and int(img.split(\".\")[0]) % 5 == 0):\n",
    "        if(int(img.split(\".\")[0]) == 170):\n",
    "           # del matrixTotal\n",
    "            matrixTotal = vector\n",
    "        else:\n",
    "            matrixTotal = np.concatenate ((matrixTotal,vector),axis = 0)\n",
    "            \n",
    "        #if(int(img.split(\".\")[0]) % 5 == 0):\n",
    "            #saveMatrix('prueba'+str(i),pathFolderResult,matrixTotal)\n",
    "            #i = i +1\n",
    "saveMatrix('prueba',pathFolderResult,matrixTotal)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####CELDAS DE PRUEBA\n",
    "\n",
    "\n",
    "img = transformarImagen(\"A/tr01_cam00/000271.png\",\"A/BN/000271.png\")\n",
    "matrix = obtenerActivacion(img)\n",
    "img2 = transformarImagen(\"A/tr01_cam00/000272.png\",\"A/BN/000272.png\")\n",
    "matrix2 = obtenerActivacion(img2)\n",
    "matrixTotal = np.concatenate ((matrix,matrix2),axis = 0)\n",
    "saveMatrix('prueba1',\"matrix/\",matrixTotal)\n",
    "print (loadMatrix('prueba1',\"matrix/\"))\n",
    "\n",
    "\n",
    "\n",
    "pathFolderRoot = \"E:/ITM/Semillero de investigación/FirstTestData\"\n",
    "\n",
    "\n",
    "imagesColor = listdir(pathFolderRoot+\"/Color/A/tr01_cam00/\")\n",
    "imagesSegment = listdir(pathFolderRoot+\"/Segmentado/A/tr01_cam00/\")\n",
    "\n",
    "i = 0\n",
    "for img in imagesColor:\n",
    "    print (img.split(\".\"))\n",
    "    if (int(img.split(\".\")[0]) > 169):\n",
    "        print (img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 4096)\n"
     ]
    }
   ],
   "source": [
    "print (matrixTotal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1\n"
     ]
    }
   ],
   "source": [
    "c = 's'\n",
    "i= 1\n",
    "b = c +str(i)\n",
    "print (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 4096)\n"
     ]
    }
   ],
   "source": [
    "pathFolderResult = \"E:/ITM/Semillero de investigación/FirstTestData/Result/\"\n",
    "mmm = loadMatrix('prueba', pathFolderResult)\n",
    "print (mmm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
